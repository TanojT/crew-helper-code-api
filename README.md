# ðŸ§  CrewCode Assistant

**CrewCode Assistant** is an enterprise-grade backend service that leverages LLMs and agentic workflows to assist developers with context-aware code generation, code updates, and modular task planning. It supports both open-source (LLaMA via Ollama) and proprietary (OpenAI GPT-4) models, orchestrated via a FastAPI application with CrewAI for dynamic agent execution.

---

## ðŸ—ï¸ Overview

CrewCode Assistant helps enterprises enhance developer productivity by automating boilerplate generation, refactoring, and best-practice enforcement through intelligent agents. The system is built to support:

- **Stateless code generation**
- **Diff-based intelligent updates**
- **Model flexibility (GPT or LLaMA)**
- **Session-based project context handling**
- **Agentic pipelines using CrewAI**

---

## âœ… Whatâ€™s Implemented

### ðŸš€ Core Features

| Feature                         | Description                                                                  |
| ------------------------------- | ---------------------------------------------------------------------------- |
| **Code Generation (Stateless)** | Accepts user input and returns language-specific, modular code               |
| **Diff Mode**                   | Updates existing code with new requirements using project-aware context      |
| **CrewAI Orchestration**        | Dynamic role-based agents (Planner, Writer, Updater) handle multi-step flows |
| **Session Context Management**  | Stores per-user/project file states (e.g., existing code, diffs) in memory   |
| **Multi-Model LLM Support**     | Supports OpenAI GPT-4 and Ollama-hosted LLaMA 3.2 models                     |
| **Markdown Output Formatting**  | Returns clean markdown code blocks, ready for frontend/editor consumption    |

---

## ðŸ› ï¸ Architecture

```
User â†’ FastAPI REST API
       â”œâ”€ Detects Mode (stateless / diff)
       â”œâ”€ Pulls context from SessionManager
       â”œâ”€ Builds prompt dynamically
       â”œâ”€ Invokes CrewAI with agents + tasks
       â””â”€ Returns formatted code output
```

---

## ðŸ“ Directory Structure

```
â”œâ”€â”€ main.py                 # FastAPI app & endpoints
â”œâ”€â”€ agents.py               # CrewAI agent definitions
â”œâ”€â”€ llm_client.py           # LLM wrappers (OpenAI / Ollama)
â”œâ”€â”€ session.py              # In-memory session manager
â”œâ”€â”€ utils.py                # Helper functions (mode detection, markdown)
â”œâ”€â”€ logger.py               # Structured logging
â”œâ”€â”€ .env                    # API keys and config (ignored)
â”œâ”€â”€ .gitignore              # Ignores venv, .env, pycache
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ README.md               # This file
```

---

## ðŸ” Security & Privacy

- No user data or code is persisted beyond in-memory sessions
- Model API keys are stored securely via `.env` and never exposed in logs
- Future: Integrate with AWS Secrets Manager / Vault for secure key rotation

---

## ðŸ§ª How to Run (Local Dev)

```bash
# Setup environment
python -m venv venv
source venv/bin/activate          # Or venv\Scripts\activate for Windows
pip install -r requirements.txt

# Add .env file
echo OPENAI_API_KEY=sk-... > .env

# Start FastAPI server
uvicorn main:app --reload
```

---

## ðŸ§© Future Roadmap

| Milestone | Description                                           |
| --------- | ----------------------------------------------------- |
| **C3**    | TTL-based session cleanup                             |
| **D**     | Agent expansion (CodeReviewer, Optimizer)             |
| **E**     | Vector database integration (for long context / RAG)  |
| **F**     | Editor integration (VSCode extension or web frontend) |
| **G**     | Authentication and multi-tenant project tracking      |

---

## ðŸ§  Vision

CrewCode Assistant is designed to evolve into a **developer co-pilot backend**, supporting IDE integrations, multi-user project memory, and enterprise-scale prompt management pipelines â€” without sacrificing model flexibility or deployment control.

---
